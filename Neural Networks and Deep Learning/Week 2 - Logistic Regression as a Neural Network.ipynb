{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Clasification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a statistical model used to give a probability of a certain class or event such as, fail/pass, dead/alive, win/lose.\n",
    "\n",
    "So let's break down this.\n",
    "\n",
    "What is a statistical model?\n",
    "\n",
    "is a mathematical model that use probability and include some assumptions from a sample data that can be applied for a population\n",
    "\n",
    "The statistical model also represent an ideal form of data-generating process\n",
    "\n",
    "ok, but the what is a mathematical model?\n",
    "\n",
    "Actually a model is a representation of a system (it described), using mathematical concepts and language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logistic Regression](assets/logisticregression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logistic regression notation](assets/logisticregreationnotation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is an algorithm for binary clasification (A learning algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logistic Regression](assets/logisticregretion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistical Regression Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to train the parameters \n",
    "- **w**\n",
    "- **b**\n",
    "\n",
    "we need to define a **cost function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cost Function](assets/CostFunction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the important here is\n",
    "### Lost Function\n",
    "- Is the value that determinate how well you're doing for a single training example\n",
    "\n",
    "### Cost Function\n",
    "- Is the value that determinate how well you're doing for a entire training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Gradient Descent allow us to minime the cost function, in other words, it improve our prediction for an entire training set.\n",
    "\n",
    "A formal concept. Gradient Descent is a first-order iterative optimization algorithm for finding the minimum of a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gradient Descent](assets/GradientDescent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gradient Descent2](assets/GradientDescent2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we use the **derivate** (slope of a function by a given point) in **gradient descent**  to calculate the minimum of a function.\n",
    "\n",
    "In other to calculate we must see first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation Graph\n",
    "![computation graph](assets/Computergraph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivates with a Computation Graph\n",
    "\n",
    "So the key takeaway from this example, is that when **computing derivatives** and computing all of these derivatives, the **most efficient way to do it** is through a **right to left** computation following the direction of the red arrows\n",
    "\n",
    "![derivates with computation graph](assets/Computingderivates.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Gradient Descent\n",
    "\n",
    "Just to recap\n",
    "\n",
    "![Logistic Regression Gradient Descent](assets/LogisticregressionRecap.png)\n",
    "\n",
    "\n",
    "![Logistic Regression Derivates](assets/LogisticRegressionDerivates.png)\n",
    "\n",
    "\n",
    "### This is algorithm to implement\n",
    "\n",
    "![Logistic Regression Algorithm](assets/LogisticRegressionAlgorithm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see the algorithm use 2 **for** loops\n",
    "- Training set\n",
    "- Gradient Descent\n",
    "\n",
    "In fact, **for** loops are not so efficient when we implement it, with a huge amount of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "Vectorization is the **art** of **get rid** of **for** loops\n",
    "\n",
    "We use vectorization because it's **much faster** than the **for** loop, an example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of values 249743.245193857\n",
      "Vectorized version 1.4030933380126953 ms \n",
      "\n",
      "Number of values 249743.24519385604\n",
      "For loop 464.6720886230469 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "a = np.random.rand(int(1e6))\n",
    "b = np.random.rand(int(1e6))\n",
    "\n",
    "tic = time.time()\n",
    "c = np.dot(a,b)\n",
    "toc = time.time()\n",
    "\n",
    "print(\"Number of values \" + str(c))\n",
    "print(\"{} {} ms \\n\".format(\"Vectorized version\", str(1000*(toc-tic))))\n",
    "\n",
    "c = 0\n",
    "tic = time.time()\n",
    "for i in range(int(1e6)):\n",
    "    c += a[i] * b[i]\n",
    "toc = time.time()\n",
    "\n",
    "print(\"Number of values \" + str(c))\n",
    "print(\"{} {} ms\".format(\"For loop\", str(1000*(toc-tic))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "What actually compute a neuron?\n",
    "\n",
    "The linear regression and the activation function (such as sigmoid, relu, ...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
